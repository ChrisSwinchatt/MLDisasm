#!/usr/bin/env python3

'''
Usage: {0} <model>
'''

import sys
import time
import traceback as tb
import warnings

# Ignore warnings generated by using a different NumPy version.
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")

if __name__ == '__main__':
    print('*** Starting up...')

import tensorflow as tf

import mldisasm.io.log as log
from   mldisasm.io.file_manager    import FileManager
from   mldisasm.model.disassembler import Disassembler

def read_command_line():
    '''
    Get the model name from the command-line.
    '''
    if len(sys.argv) != 2:
        print(__doc__.format(sys.argv[0]), file=sys.stderr)
        exit(1)
    return sys.argv[1]

def select_device(config):
    '''
    Select a TensorFlow device according to configuration.
    '''
    log.info('Checking TensorFlow device configuration (this can take some time)')
    preferred = config['preferred_device']
    fallback = config['fallback_device']
    if 'gpu' in preferred.lower() and not tf.test.is_gpu_available():
        if fallback is None:
            log.error('Preferred device \'{}\' is not available and no fallback device was specified, stopping.')
            exit(1)
        log.warning('Preferred device \'{}\' is not available, falling back to \'{}\''.format(
            preferred,
            fallback
        ))
        return fallback
    log.info('Running TensorFlow on preferred device \'{}\''.format(preferred))
    return preferred

def train_model(tset, n_epochs, session=None):
    '''
    Train a model.
    '''
    # Create a model.
    model = Disassembler(**config['model'])
    for epoch in range(1, n_epochs + 1):
        log.info('Starting epoch {}/{}'.format(epoch, n_epochs))
        total_loss = 0
        start = time.time()
        batch = 1
        while True:
            try:
                X, y = tset.next_batch()
            except StopIteration:
                break
            log.debug('Batch {}/{} (batch size={})'.format(
                batch,
                int(len(tset)/tset.batch_size),
                tset.batch_size
            ))
            total_loss = model.train(X, y)
            if session:
                session.run(total_loss)
            batch += 1
        elapsed = time.time() - start
        log.info('Epoch {} finished in {:f} sec with loss={}'.format(
            epoch,
            elapsed,
            total_loss
        ))

def start_training(tset, config):
    '''
    Train a model within a TF session.
    '''
    device   = select_device(config)
    n_epochs = config['epochs']
    with tf.device(device), tf.Session() as session:
        train_model(tset, n_epochs, session)

if __name__ == '__main__':
    # Read command-line args.
    model_name = read_command_line()
    # Start file manager and logging/
    file_mgr   = FileManager()
    log.init(file_mgr.open_log())
    try:
        # Read configuration & load training set.
        config = file_mgr.load_config(model_name)
        tset   = file_mgr.open_training(model_name)
        tset.batch_size = config['batch_size']
        # Begin training.
        start_training(tset, config)
    except Exception as e:
        log.debug('====================[ UNCAUGHT EXCEPTION ]====================')
        log.error('Uncaught exception \'{}\': {}. See the log at {} for details.'.format(
            type(e).__name__,
            ' '.join(e.args),
            file_mgr.log_file_path
        ))
        log.debug('Exception Traceback:\n{}'.format(''.join(tb.format_tb(e.__traceback__))))
        exit(1)
