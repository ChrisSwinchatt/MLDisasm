#!/usr/bin/env python3

'''Usage: {0} <model>
'''

import os
import random
import sys
import traceback as tb
import warnings

import numpy as np

# Filter out debug messages from TF.
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'

# Ignore warnings generated by using a different NumPy version.
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")

if __name__ == '__main__':
    print('*** Starting up...')

import tensorflow               as tf
import tensorflow.keras.backend as K

from mldisasm.io.codec        import AsciiCodec, BytesCodec
from mldisasm.io.file_manager import FileManager
from mldisasm.util            import log, prof, refresh_graph
from mldisasm.util.force_cpu  import force_cpu
from mldisasm.training        import parameter_grid, kfolds_train

# Force TF to use the CPU.
force_cpu()

RANDOM_SEED = 1

def tune_model(config, params, file_mgr, model_name, codecs):
    '''
    Train a model with a set of parameters and return the average accuracy and loss during cross-validation.
    '''
    # Seed PRNG with a fixed value so each model gets the same sequence of numbers.
    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    tf.set_random_seed(RANDOM_SEED)
    # Create training set generator and train with kfolds.
    batches = file_mgr.yield_training(
        model_name,
        codecs,
        params['batch_size'],
        loop_mode   = True,
        max_records = config['gs_records']
    )
    acc, loss = kfolds_train(batches, params, num_batches=config['gs_records']//params['batch_size'])
    # Clean up the TF graph.
    refresh_graph()
    return acc, loss

def select_params(config, file_mgr, model_name, codecs):
    '''
    Select hyperparameters by gridsearch with cross-validation.
    '''
    log.info('Selecting hyperparameters')
    grid = parameter_grid(config['grid'])
    if len(grid) == 0:
        log.error('No parameters to tune. Stopping.')
        exit(0)
    fit_num     = 1
    num_fits    = len(grid)
    best_params = None
    best_acc    = -np.inf
    acc         = 0
    loss        = 0
    for grid_params in grid:
        with prof(
            'Grid {}/{}: acc={}%, loss={}', fit_num, num_fits, lambda: 100*acc, lambda: round(loss, 4),
            log_level='info',
            start_msg='Grid {}/{}: {}'.format(fit_num, num_fits, grid_params)
        ):
            params = dict(config['model'])
            params.update(grid_params)
            acc, loss = tune_model(config, params, file_mgr, model_name, codecs)
            # Select model by accuracy.
            if acc > best_acc:
                best_acc = acc
                best_params = params
            fit_num += 1
    assert best_params is not None
    log.info('Best accuracy was {}% with parameters {}'.format(round(best_acc*100, 2), best_params))
    return best_params

def read_command_line():
    '''
    Get the model name from the command-line.
    '''
    if len(sys.argv) != 2:
        print(__doc__.format(sys.argv[0]), file=sys.stderr)
        exit(1)
    return sys.argv[1]

if __name__ == '__main__':
    K.set_learning_phase(1)
    # Read command-line args.
    model_name = read_command_line()
    # Start file manager & logging.
    tf.logging.set_verbosity(tf.logging.INFO)
    file_mgr = FileManager()
    log.init(file_mgr.open_log())
    # Train a model.
    try:
        # Load configuration and set TF device.
        config  = file_mgr.load_config(model_name)
        x_codec = BytesCodec(config['model']['x_seq_len'], config['model']['mask_value'])
        y_codec = AsciiCodec(config['model']['y_seq_len'], config['model']['mask_value'])
        # Find and save hyperparameters.
        K.set_learning_phase(1)
        config['model'] = select_params(config, file_mgr, model_name, (x_codec,y_codec))
        del config['grid']
        file_mgr.save_config(model_name, config)
    except Exception as e:
        log.debug('====================[ UNCAUGHT EXCEPTION ]====================')
        log.error('Uncaught exception \'{}\': {}'.format(type(e).__name__, str(e).split('\n')[0]))
        log.error('See the log at {} for details.'.format(file_mgr.log_file_path))
        log.debug('Exception Traceback:\n{}'.format(''.join(tb.format_tb(e.__traceback__))))
        exit(1)
